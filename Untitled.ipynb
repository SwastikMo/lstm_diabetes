{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb701b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import loadtxt\n",
    "dataset = loadtxt(\"pima-indians-diabetes.csv\",delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "559721f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
       "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
       "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
       "       ...,\n",
       "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
       "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
       "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b0790c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8760d84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"pima-indians-diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29ddbf11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6</th>\n",
       "      <th>148</th>\n",
       "      <th>72</th>\n",
       "      <th>35</th>\n",
       "      <th>0</th>\n",
       "      <th>33.6</th>\n",
       "      <th>0.627</th>\n",
       "      <th>50</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>767 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      6  148  72  35    0  33.6  0.627  50  1\n",
       "0     1   85  66  29    0  26.6  0.351  31  0\n",
       "1     8  183  64   0    0  23.3  0.672  32  1\n",
       "2     1   89  66  23   94  28.1  0.167  21  0\n",
       "3     0  137  40  35  168  43.1  2.288  33  1\n",
       "4     5  116  74   0    0  25.6  0.201  30  0\n",
       "..   ..  ...  ..  ..  ...   ...    ...  .. ..\n",
       "762  10  101  76  48  180  32.9  0.171  63  0\n",
       "763   2  122  70  27    0  36.8  0.340  27  0\n",
       "764   5  121  72  23  112  26.2  0.245  30  0\n",
       "765   1  126  60   0    0  30.1  0.349  47  1\n",
       "766   1   93  70  31    0  30.4  0.315  23  0\n",
       "\n",
       "[767 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1558a4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no column names given "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6eafbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X =X.reshape(X.shape[0], X.shape[1]//2,2)\n",
    "# converting the data model into 3 dimensional space and 2 time stamps for LSTM to train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfb06ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  6.   , 148.   ],\n",
       "        [ 72.   ,  35.   ],\n",
       "        [  0.   ,  33.6  ],\n",
       "        [  0.627,  50.   ]],\n",
       "\n",
       "       [[  1.   ,  85.   ],\n",
       "        [ 66.   ,  29.   ],\n",
       "        [  0.   ,  26.6  ],\n",
       "        [  0.351,  31.   ]],\n",
       "\n",
       "       [[  8.   , 183.   ],\n",
       "        [ 64.   ,   0.   ],\n",
       "        [  0.   ,  23.3  ],\n",
       "        [  0.672,  32.   ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  5.   , 121.   ],\n",
       "        [ 72.   ,  23.   ],\n",
       "        [112.   ,  26.2  ],\n",
       "        [  0.245,  30.   ]],\n",
       "\n",
       "       [[  1.   , 126.   ],\n",
       "        [ 60.   ,   0.   ],\n",
       "        [  0.   ,  30.1  ],\n",
       "        [  0.349,  47.   ]],\n",
       "\n",
       "       [[  1.   ,  93.   ],\n",
       "        [ 70.   ,  31.   ],\n",
       "        [  0.   ,  30.4  ],\n",
       "        [  0.315,  23.   ]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f14ffab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 4, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e1679ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.12.0-cp310-cp310-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.12.0\n",
      "  Downloading tensorflow_intel-2.12.0-cp310-cp310-win_amd64.whl (272.8 MB)\n",
      "     -------------------------------------- 272.8/272.8 MB 7.1 MB/s eta 0:00:00\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.0-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "     --------------------------------------- 24.4/24.4 MB 27.3 MB/s eta 0:00:00\n",
      "Collecting keras<2.13,>=2.12.0\n",
      "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 5.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 65.5/65.5 kB 3.5 MB/s eta 0:00:00\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-23.3.3-py2.py3-none-any.whl (26 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.23.5)\n",
      "Collecting tensorflow-estimator<2.13,>=2.12.0\n",
      "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
      "     -------------------------------------- 440.7/440.7 kB 3.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.54.0-cp310-cp310-win_amd64.whl (4.1 MB)\n",
      "     ---------------------------------------- 4.1/4.1 MB 32.7 MB/s eta 0:00:00\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.5/57.5 kB ? eta 0:00:00\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.22.4-cp310-abi3-win_amd64.whl (420 kB)\n",
      "     ------------------------------------- 420.6/420.6 kB 13.2 MB/s eta 0:00:00\n",
      "Collecting tensorboard<2.13,>=2.12\n",
      "  Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
      "     ---------------------------------------- 5.6/5.6 MB 32.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.4.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 15.7 MB/s eta 0:00:00\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "     -------------------------------------- 126.5/126.5 kB 7.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (22.0)\n",
      "Collecting jax>=0.3.15\n",
      "  Downloading jax-0.4.8.tar.gz (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 26.2 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: setuptools in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (65.6.3)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.38.4)\n",
      "Collecting ml-dtypes>=0.0.3\n",
      "  Downloading ml_dtypes-0.1.0-cp310-cp310-win_amd64.whl (120 kB)\n",
      "     -------------------------------------- 120.4/120.4 kB 7.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.10.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.0-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.17.3-py2.py3-none-any.whl (178 kB)\n",
      "     ------------------------------------- 178.2/178.2 kB 11.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.2.8)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     ---------------------------------------- 151.7/151.7 kB ? eta 0:00:00\n",
      "Building wheels for collected packages: jax\n",
      "  Building wheel for jax (pyproject.toml): started\n",
      "  Building wheel for jax (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for jax: filename=jax-0.4.8-py3-none-any.whl size=1439795 sha256=b6469c9cbb8d6469f3a7e27b67efb43beb2cb48a9a08ba201883809599888ac9\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\d6\\f6\\d5\\63686989c723075de411cbc630ca12f4241a8436e411e38d6a\n",
      "Successfully built jax\n",
      "Installing collected packages: libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, protobuf, opt-einsum, oauthlib, ml-dtypes, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, jax, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.0 flatbuffers-23.3.3 gast-0.4.0 google-auth-2.17.3 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.54.0 jax-0.4.8 keras-2.12.0 libclang-16.0.0 ml-dtypes-0.1.0 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.22.4 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.12.3 tensorboard-data-server-0.7.0 tensorflow-2.12.0 tensorflow-estimator-2.12.0 tensorflow-intel-2.12.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39e7da85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization , LSTM , Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "21067c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(\n",
    "    LSTM(\n",
    "        1,\n",
    "        activation = 'tanh',\n",
    "        input_shape = (X.shape[1],2),\n",
    "        dropout = 0.5 , \n",
    "        return_sequences = True\n",
    "    ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy' ,\n",
    "              optimizer = 'adam',\n",
    "              metrics =['accuracy','BinaryAccuracy'] ) \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8a37cfbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_22 (LSTM)              (None, 4, 1)              16        \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 4, 1)             4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " lstm_23 (LSTM)              (None, 1)                 12        \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 1)                4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38\n",
      "Trainable params: 34\n",
      "Non-trainable params: 4\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "89af1d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "39/39 [==============================] - 4s 4ms/step - loss: 0.7257 - accuracy: 0.5286 - binary_accuracy: 0.5286\n",
      "Epoch 2/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.7366 - accuracy: 0.5013 - binary_accuracy: 0.5013\n",
      "Epoch 3/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.7176 - accuracy: 0.5143 - binary_accuracy: 0.5143\n",
      "Epoch 4/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6997 - accuracy: 0.5586 - binary_accuracy: 0.5586\n",
      "Epoch 5/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6891 - accuracy: 0.5586 - binary_accuracy: 0.5586\n",
      "Epoch 6/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6945 - accuracy: 0.5417 - binary_accuracy: 0.5417\n",
      "Epoch 7/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6722 - accuracy: 0.5716 - binary_accuracy: 0.5716\n",
      "Epoch 8/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6759 - accuracy: 0.5677 - binary_accuracy: 0.5677\n",
      "Epoch 9/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6766 - accuracy: 0.5703 - binary_accuracy: 0.5703\n",
      "Epoch 10/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6601 - accuracy: 0.6094 - binary_accuracy: 0.6094\n",
      "Epoch 11/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6677 - accuracy: 0.5977 - binary_accuracy: 0.5977\n",
      "Epoch 12/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6699 - accuracy: 0.6094 - binary_accuracy: 0.6094\n",
      "Epoch 13/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6576 - accuracy: 0.6198 - binary_accuracy: 0.6198\n",
      "Epoch 14/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6528 - accuracy: 0.6432 - binary_accuracy: 0.6432\n",
      "Epoch 15/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6575 - accuracy: 0.6484 - binary_accuracy: 0.6484\n",
      "Epoch 16/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6579 - accuracy: 0.6367 - binary_accuracy: 0.6367\n",
      "Epoch 17/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6571 - accuracy: 0.6393 - binary_accuracy: 0.6393\n",
      "Epoch 18/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6545 - accuracy: 0.6263 - binary_accuracy: 0.6263\n",
      "Epoch 19/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6561 - accuracy: 0.6484 - binary_accuracy: 0.6484\n",
      "Epoch 20/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6520 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 21/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6499 - accuracy: 0.6536 - binary_accuracy: 0.6536\n",
      "Epoch 22/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6555 - accuracy: 0.6471 - binary_accuracy: 0.6471\n",
      "Epoch 23/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6516 - accuracy: 0.6523 - binary_accuracy: 0.6523\n",
      "Epoch 24/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6518 - accuracy: 0.6536 - binary_accuracy: 0.6536\n",
      "Epoch 25/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6525 - accuracy: 0.6497 - binary_accuracy: 0.6497\n",
      "Epoch 26/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6517 - accuracy: 0.6523 - binary_accuracy: 0.6523\n",
      "Epoch 27/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6497 - accuracy: 0.6497 - binary_accuracy: 0.6497\n",
      "Epoch 28/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6510 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 29/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6512 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 30/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6509 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 31/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6519 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 32/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6451 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 33/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6501 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 34/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6442 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 35/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6484 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 36/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6499 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 37/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6470 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 38/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6486 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 39/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6511 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 40/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6486 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 41/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6502 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 42/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6458 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 43/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6501 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 44/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6487 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 45/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6458 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 46/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6492 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 47/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6489 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 48/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6483 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 49/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6464 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 50/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6495 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 51/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6463 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 52/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6469 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 53/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6475 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 54/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6478 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 55/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6467 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 56/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6485 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 57/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6471 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 58/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6484 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 59/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6484 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 60/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6485 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 61/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6454 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 62/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6482 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 63/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6481 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 64/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6456 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 65/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6471 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6473 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 67/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6483 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 68/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6463 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 69/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6460 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 70/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6477 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 71/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6488 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 72/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6467 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 73/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6474 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 74/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6458 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 75/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6463 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 76/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6449 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 77/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6471 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 78/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6469 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 79/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6453 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 80/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 0.6465 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 81/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.6461 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 82/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.6476 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 83/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.6475 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 84/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.6459 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 85/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.6482 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 86/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.6467 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 87/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.6471 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 88/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.6468 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 89/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.6469 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 90/100\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.6455 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 91/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.6474 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 92/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.6471 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 93/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.6476 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 94/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.6480 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 95/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.6471 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 96/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.6468 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 97/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.6464 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 98/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.6461 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 99/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.6467 - accuracy: 0.6510 - binary_accuracy: 0.6510\n",
      "Epoch 100/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.6479 - accuracy: 0.6510 - binary_accuracy: 0.6510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x266eb563190>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,Y,epochs = 100 ,batch_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59a19ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
